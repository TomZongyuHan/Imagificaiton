{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca78ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.fft import fft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Activation, Dense, MaxPooling2D, Flatten\n",
    "from Transformer import ImageTransformer, LogScaler\n",
    "from scipy.linalg import block_diag\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt  # matplotlib.pyplot is used for plotting a figure in the same way with matlab and making some change on it.\n",
    "import warnings  # ''ignore'' means not important warning to stop the program. \"never print matching warnings\"\n",
    "import cv2\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"  # rcpParams Tips for customizing the properties and default styles of Matplotlib.\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_fft(x, it):  # fast fourier transform\n",
    "    b = fft(x)  # If X is a matrix, then fft(X) treats the columns of X as vectors and returns the Fourier transform of each column.\n",
    "    b_real = b.real\n",
    "    b_real = np.where(b_real < 0, b_real, 0)\n",
    "\n",
    "    b_imag = b.imag\n",
    "    b_imag = np.where(b_imag < 0, b_imag, 0)\n",
    "\n",
    "    scale_fft = LogScaler()  # Log normalize and scale data\n",
    "    b_real_norm = scale_fft.fit_transform(np.abs(b_real + 1))\n",
    "    b_imag_norm = scale_fft.fit_transform(np.abs(b_imag + 1))\n",
    "\n",
    "    x_fft_real = it.transform(b_real_norm);\n",
    "    x_fft_imag = it.transform(b_imag_norm);\n",
    "\n",
    "    return x_fft_real, x_fft_imag\n",
    "\n",
    "def classifiers(x_train, x_test, train_label, test_label):\n",
    "    # SVM\n",
    "    svm_clf = svm.SVC()\n",
    "    svm_clf.fit(x_train, train_label)\n",
    "    svm_pred_label = svm_clf.predict(x_test)\n",
    "    svm_acc = accuracy_score(test_label, svm_pred_label)\n",
    "    svm_f1 = f1_score(test_label, svm_pred_label, average='micro')\n",
    "\n",
    "    # RF\n",
    "    rf_clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    rf_clf.fit(x_train, train_label)\n",
    "    rf_pred_label = rf_clf.predict(x_test)\n",
    "    rf_acc = accuracy_score(test_label, rf_pred_label)\n",
    "    rf_f1 = f1_score(test_label, rf_pred_label, average='micro')\n",
    "\n",
    "    #KNN\n",
    "    knn_cls = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_cls.fit(x_train, train_label)\n",
    "    knn_pred_label = knn_cls.predict(x_test)\n",
    "    knn_acc = accuracy_score(test_label, knn_pred_label)\n",
    "    knn_f1 = f1_score(test_label, knn_pred_label, average='micro')\n",
    "\n",
    "    return svm_acc, svm_f1, rf_acc, rf_f1, knn_acc, knn_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa44596",
   "metadata": {},
   "source": [
    "# Stage 1: Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439350b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#################################### Stage 1 #####################################\n",
    "Stage 1: Data preparation for data/${train_set}, data/${valid_set}, etc.\n",
    "\"\"\"\n",
    "print(\"#################### Stage 1: Data preparation #####################\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "fileName = 'TabulaMuris_Tongue_FACS-RawCount-new.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7cd8ea",
   "metadata": {},
   "source": [
    "## Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97be5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data clean\n",
    "filepath = 'Datasets/RowCount/new/' + fileName if '-RawCount-new' in fileName else 'Datasets/RowCount/' + fileName\n",
    "Dataset = pd.read_csv(filepath, index_col=0, header=None, dtype='unicode').T\n",
    "Dataset = Dataset.rename(columns={Dataset.columns[0]: 'Unnamed: 0'})\n",
    "Dataset.drop(columns=['Unnamed: 0'], inplace=True)  # omitting the first column consist of feature names\n",
    "if 'NA' in Dataset.columns: Dataset.drop(columns=['NA'], inplace=True)\n",
    "Dataset.dropna(inplace=True)  # Drop rows with missing indices or values.(drop all missing data)\n",
    "\n",
    "labels = np.array(Dataset.columns.tolist())  # Get list from pandas dataframe column or row\n",
    "for i in range(len(labels)):\n",
    "    labels[i] = ''.join(labels[i].split('.'))\n",
    "\n",
    "data = Dataset.T.values  # Pandas DataFrame.values attribute return a Numpy representation of the given DataFrame.\n",
    "# data = data.astype('int64')\n",
    "data = data.astype('float64')\n",
    "\n",
    "print('len of unique classes: ' + str(len(list(set(labels)))))\n",
    "print('Input Type: ' + str(type(data[0][0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e6e09",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test split\n",
    "classes, indices = np.unique(labels, return_inverse=True)\n",
    "X_Train, X_Test, y_train, y_test, train_label, test_label = train_test_split(\n",
    "    data, labels, indices, test_size=0.2, random_state=23, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75655eaa",
   "metadata": {},
   "source": [
    "## Calculate svm_acc, svm_f1, rf_acc, rf_f1, knn_acc, knn_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc, svm_f1, rf_acc, rf_f1, knn_acc, knn_f1 = classifiers(X_Train, X_Test, train_label, test_label)\n",
    "print(\"SVM Acc: {}, SVM F1: {}, RF Acc: {}, RF F1: {}, KNN Acc: {}, KNN F1: {}\"\n",
    "    .format(svm_acc, svm_f1, rf_acc, rf_f1, knn_acc, knn_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94654cae",
   "metadata": {},
   "source": [
    "## Prepare for Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LogScaler()  # Log normalize and scale data\n",
    "X_train = ln.fit_transform(X_Train)\n",
    "X_test = ln.transform(X_Test)\n",
    "\n",
    "# prepare frames\n",
    "train_frames = []\n",
    "for i in range(len(classes)):\n",
    "    train_frame = X_train[np.where(train_label == i)[0], :]\n",
    "    train_frames.append(train_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53976151",
   "metadata": {},
   "source": [
    "# Stage 2: Apply Transformer and get fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a01204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#################################### Stage 2 #####################################\n",
    "Stage 2: Apply Transformer and get fitters\n",
    "'''\n",
    "print(\"#################### Stage 2: Apply Transformer #####################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723636cb",
   "metadata": {},
   "source": [
    "## Apply Transformer and get fitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Transformer and get fitters\n",
    "fitters = []\n",
    "for i in range(len(classes)):\n",
    "    it = ImageTransformer(feature_extractor='tsne',\n",
    "                        pixels=100, random_state=12345,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "    train_frame = np.array(train_frames[i])\n",
    "\n",
    "    _ = it.fit(train_frame, plot=False)\n",
    "\n",
    "    fitters.append(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0096c9",
   "metadata": {},
   "source": [
    "## Prepare training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training images\n",
    "Pixel = 100\n",
    "x_train_img_fft = np.zeros((len(X_train), len(classes) * Pixel + 1, len(classes) * Pixel, 3))\n",
    "for j in range(len(X_train)):\n",
    "    train_frame = X_train[j]\n",
    "    class_data = []\n",
    "    block_img_0 = []\n",
    "    block_img_1 = []\n",
    "    block_img_2 = []\n",
    "    for it in fitters:\n",
    "        x_train_img = it.transform(X_train[j])\n",
    "        block_img_0 = block_diag(block_img_0, x_train_img[0, :, :, 0])\n",
    "\n",
    "        x_train_fft_real, x_train_fft_imag = b_fft(train_frame, it)\n",
    "        block_img_1 = block_diag(block_img_1, x_train_fft_real[0, :, :, 0])\n",
    "        block_img_2 = block_diag(block_img_2, x_train_fft_imag[0, :, :, 0])\n",
    "\n",
    "    x_train_img_fft[j, :, :, 0] = block_img_0\n",
    "    x_train_img_fft[j, :, :, 1] = block_img_1\n",
    "    x_train_img_fft[j, :, :, 2] = block_img_2\n",
    "\n",
    "x_train_img_fft[x_train_img_fft > 1] = 1\n",
    "X_train_imgs = x_train_img_fft\n",
    "\n",
    "y_predict_label = []\n",
    "x_test_img_fft = np.zeros((len(X_test), len(classes) * Pixel + 1, len(classes) * Pixel, 3))\n",
    "for j in range(len(X_test)):\n",
    "    test_frame = X_test[j]\n",
    "    class_data = []\n",
    "    block_img_0 = []\n",
    "    block_img_1 = []\n",
    "    block_img_2 = []\n",
    "    for it in fitters:\n",
    "        x_test_img = it.transform(X_test[j])\n",
    "        block_img_0 = block_diag(block_img_0, x_test_img[0, :, :, 0])\n",
    "\n",
    "        x_test_fft_real, x_test_fft_imag = b_fft(test_frame, it)\n",
    "        block_img_1 = block_diag(block_img_1, x_test_fft_real[0, :, :, 0])\n",
    "        block_img_2 = block_diag(block_img_2, x_test_fft_imag[0, :, :, 0])\n",
    "\n",
    "    x_test_img_fft[j, :, :, 0] = block_img_0\n",
    "    x_test_img_fft[j, :, :, 1] = block_img_1\n",
    "    x_test_img_fft[j, :, :, 2] = block_img_2\n",
    "\n",
    "x_test_img_fft[x_test_img_fft > 1] = 1\n",
    "X_test_imgs = x_test_img_fft\n",
    "\n",
    "print('Shape of X_train_imgs: ' + str(X_train_imgs.shape))\n",
    "print('Shape of X_test_imgs: ' + str(X_test_imgs.shape))\n",
    "\n",
    "image_time = time.time()\n",
    "imag_run_time = image_time - start_time\n",
    "print(' image_run_time: ' + str(imag_run_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9b1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imgs_cp = X_train_imgs\n",
    "X_test_imgs_cp = X_test_imgs\n",
    "\n",
    "\n",
    "X_train_imgs_resize = []\n",
    "X_test_imgs_resize = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTER_NEAREST - a nearest-neighbor interpolation\n",
    "# INTER_LINEAR - a bilinear interpolation (used by default)\n",
    "# INTER_AREA - resampling using pixel area relation. It may be a preferred method for image decimation, as it gives moire’-free results. But when the image is zoomed, it is similar to the INTER_NEAREST method.\n",
    "# INTER_CUBIC - a bicubic interpolation over 4x4 pixel neighborhood\n",
    "# INTER_LANCZOS4 - a Lanczos interpolation over 8x8 pixel neighborhood\n",
    "\n",
    "for i in range(len(X_train_imgs_cp)):\n",
    "    X_train_imgs_resize.append(cv2.resize(X_train_imgs_cp[i], dsize=(200, 200), interpolation=cv2.INTER_LANCZOS4))\n",
    "\n",
    "for i in range(len(X_test_imgs_cp)):\n",
    "    X_test_imgs_resize.append(cv2.resize(X_test_imgs_cp[i], dsize=(200, 200), interpolation=cv2.INTER_LANCZOS4))\n",
    "\n",
    "X_train_imgs_resize = np.array(X_train_imgs_resize)\n",
    "X_test_imgs_resize = np.array(X_test_imgs_resize)\n",
    "\n",
    "print('Shape of X_train_imgs_resize: ' + str(X_train_imgs_resize.shape))\n",
    "print('Shape of X_test_imgs_resize: ' + str(X_test_imgs_resize.shape))\n",
    "\n",
    "resiz_time = time.time()\n",
    "resize_time = resiz_time - image_time\n",
    "print(' imgresize_run_time: ' + str(resize_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f60e8",
   "metadata": {},
   "source": [
    "# Stage 3: Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#################################### Stage 3 #####################################\n",
    "Stage 3: Train CNN Model\n",
    "'''\n",
    "print(\"#################### Stage 3: Training #####################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f915e4",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ff1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X_train_imgs_resize[0].shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(len(classes)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1, min_delta=1e-4, mode='auto')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f260696",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727ccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_imgs_resize, train_label, batch_size=32, epochs=90, verbose=1,\n",
    "        callbacks=[earlyStopping, mcp_save, reduce_lr_loss],\n",
    "        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15273a1f",
   "metadata": {},
   "source": [
    "# Stage 4: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#################################### Stage 4 #####################################\n",
    "Stage 4: Evaluation\n",
    "'''\n",
    "print(\"#################### Stage 4: Evaluation #####################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred_0 = model.predict(X_test_imgs_resize)\n",
    "y_predict_label = np.argmax(y_pred_0, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_predict_label, test_label)\n",
    "f1_mac = f1_score(y_predict_label, test_label, average='macro')\n",
    "f1_mic = f1_score(y_predict_label, test_label, average='macro')\n",
    "f1_wght = f1_score(y_predict_label, test_label, average='macro')\n",
    "sensitivity_mac = recall_score(y_predict_label, test_label, average='macro')\n",
    "sensitivity_mic = recall_score(y_predict_label, test_label, average='micro')\n",
    "sensitivity_wght = recall_score(y_predict_label, test_label, average='micro')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_predict_label, test_label, labels=[0, 1]).ravel()\n",
    "specificity = tp/(tn+fp)\n",
    "\n",
    "end_time = time.time()\n",
    "running_time = end_time - start_time\n",
    "cnn_time = end_time - resiz_time\n",
    "\n",
    "print(fileName + ' Accuracy: ' + str(acc))\n",
    "print(fileName + ' specificity: ' + str(specificity))\n",
    "print(' run_time: ' + str(running_time))\n",
    "print(' cnn_run_time: ' + str(cnn_time))\n",
    "\n",
    "print(\"f1_mac: {}, f1_mic: {}, f1_wght: {}\".format(f1_mac, f1_mic, f1_wght))\n",
    "print(\"sensitivity_mac: {}, sensitivity_mic: {}, sensitivity_wght: {}\".format(sensitivity_mac, sensitivity_mic, sensitivity_wght))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a2186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
